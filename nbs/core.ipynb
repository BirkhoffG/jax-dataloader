{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core API\n",
    "\n",
    "> Support various dataloader for loading batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "from nbdev import show_doc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 15:13:36.437449: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-26 15:13:36.437528: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-26 15:13:36.439236: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-26 15:13:37.500782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from __future__ import print_function, division, annotations\n",
    "from jax_dataloader.imports import *\n",
    "from jax_dataloader.utils import *\n",
    "from jax_dataloader.datasets import *\n",
    "from jax_dataloader.loaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "SUPPORTED_DATASETS = [\n",
    "    JAXDataset,\n",
    "    TorchDataset,\n",
    "    TFDataset,\n",
    "    HFDataset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass(frozen=True)\n",
    "class DataloaderBackends:\n",
    "    jax = DataLoaderJAX\n",
    "    pytorch: BaseDataLoader = DataLoaderPytorch\n",
    "    tensorflow: BaseDataLoader = DataLoaderTensorflow\n",
    "    merlin: BaseDataLoader = None\n",
    "\n",
    "    __all__ = dict(\n",
    "        jax=jax, pytorch=pytorch, tensorflow=tensorflow, merlin=merlin\n",
    "    )\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.__all__[key]\n",
    "\n",
    "    @property\n",
    "    def supported(self) -> List[str]:\n",
    "        return [\n",
    "            backend for backend, dl_cls in self.__all__.items() if dl_cls is not None\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_backends() -> List[str]:\n",
    "    \"\"\"Return list of supported dataloader backends\"\"\"\n",
    "    return DataloaderBackends().__all__.keys()\n",
    "\n",
    "\n",
    "def _dispatch_dataloader(\n",
    "    backend: str # dataloader backend\n",
    ") -> BaseDataLoader:\n",
    "    \"\"\"Return Dataloader class based on given `backend`\"\"\"\n",
    "    backends = DataloaderBackends()\n",
    "    if not backend in backends.supported:\n",
    "        raise ValueError(f\"backend=`{backend}` is either an invalid backend or not supported yet. \"\n",
    "            f\"Should be one of {backends.supported}.\")\n",
    "    \n",
    "    dl_cls = backends[backend]\n",
    "    return dl_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _check_backend_compatibility(ds, backend: str):\n",
    "    return DataLoader(ds, backend=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_backend_compatibilities() -> dict[str, list[type]]:\n",
    "\n",
    "    ds = {\n",
    "        JAXDataset: ArrayDataset(np.array([1,2,3])),\n",
    "        TorchDataset: torch_data.Dataset(),\n",
    "        TFDataset: tf.data.Dataset.from_tensor_slices(np.array([1,2,3])),\n",
    "        HFDataset: hf_datasets.Dataset.from_dict({'a': [1,2,3]})\n",
    "    }\n",
    "    assert len(ds) == len(SUPPORTED_DATASETS)\n",
    "    backends = {b: [] for b in _get_backends()}\n",
    "    for b in _get_backends():\n",
    "        for name, dataset in ds.items():\n",
    "            try:\n",
    "                _check_backend_compatibility(dataset, b)\n",
    "                backends[b].append(name)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataLoader:\n",
    "    \"\"\"Main Dataloader class to load Numpy data batches\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset, # Dataset or Pytorch Dataset or HuggingFace Dataset\n",
    "        backend: str, # Dataloader backend\n",
    "        batch_size: int = 1,  # batch size\n",
    "        shuffle: bool = False,  # if true, dataloader shuffles before sampling each batch\n",
    "        drop_last: bool = False, # drop last batches or not\n",
    "        **kwargs\n",
    "    ):\n",
    "        dl_cls = _dispatch_dataloader(backend)\n",
    "        self.dataloader = dl_cls(\n",
    "            dataset=dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=shuffle, \n",
    "            drop_last=drop_last,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "\n",
    "    def __next__(self):\n",
    "        return next(self.dataloader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Minimum Example of using Dataloader\n",
    "\n",
    "We showcase how to use `Dataloader` for training a simple regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import optax\n",
    "import haiku as hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=500, n_features=20)\n",
    "dataset = ArrayDataset(X, y.reshape(-1, 1))\n",
    "keys = hk.PRNGSequence(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `loss`, `step`, `train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w, x, y):\n",
    "    return jnp.mean(vmap(optax.l2_loss)(x @ w.T, y))\n",
    "\n",
    "def step(w, x, y):\n",
    "    lr = 0.1\n",
    "    grad = jax.grad(loss)(w, x, y)\n",
    "    w -= lr * grad\n",
    "    return w\n",
    "\n",
    "def train(dataloader: DataLoader, key: jax.random.PRNGKey):\n",
    "    w = jrand.normal(key, shape=(1, 20))\n",
    "    n_epochs = 10\n",
    "    for _ in range(n_epochs):\n",
    "        for x, y in dataloader:\n",
    "            w = step(w, x, y)\n",
    "    return w\n",
    "\n",
    "def eval(dataloader: DataLoader, w):\n",
    "    err = []\n",
    "    for x, y in dataloader:\n",
    "        err.append(loss(w, x, y))\n",
    "    return np.mean(err)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train this linear regression model via `DataLoaderJAX`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset, 'jax', batch_size=128, shuffle=True)\n",
    "w = train(dataloader, next(keys)).block_until_ready()\n",
    "# assert np.allclose(eval(dataloader, w), 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, 'jax', batch_size=200, shuffle=True)\n",
    "w = train(dataloader, next(keys)).block_until_ready()\n",
    "# assert np.allclose(eval(dataloader, w), 0.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train this linear regression model via `pytorch` backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "dataloader = DataLoader(\n",
    "    dataset, 'pytorch', batch_size=128, shuffle=True)\n",
    "w = train(dataloader, next(keys)).block_until_ready()\n",
    "# assert np.allclose(eval(dataloader, w), 0.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train this linear regression model via `jax` backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| tf\n",
    "dataloader = DataLoader(\n",
    "    dataset, 'tensorflow', batch_size=128, shuffle=True)\n",
    "w = train(dataloader, next(keys)).block_until_ready()\n",
    "# assert np.allclose(eval(dataloader, w), 0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
