{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp, random as jrand, tree_util as jt\n",
    "import optax\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "# nn specific\n",
    "import flax.linen as nn\n",
    "\n",
    "# data specific\n",
    "import jax_dataloader as jdl\n",
    "import torchvision\n",
    "\n",
    "# utils\n",
    "import functools as ft\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, x): # (H, W, C)\n",
    "        return np.array(x) / 255.0\n",
    "    \n",
    "@dataclass\n",
    "class Normalize:\n",
    "    mean: list[float] \n",
    "    std: list[float]\n",
    "    inplace: bool = False\n",
    "\n",
    "    def __call__(self, x: np.ndarray):\n",
    "        if x.ndim < 3:\n",
    "            raise ValueError(\n",
    "                f\"Expected tensor to be a tensor image of size (..., C, H, W). \"\n",
    "                f\"Got x.shape = {x.shape}\"\n",
    "            )\n",
    "        if not self.inplace:\n",
    "            x = x.copy()\n",
    "        \n",
    "        dtype = x.dtype\n",
    "        mean = np.asarray(self.mean, dtype=dtype)\n",
    "        std = np.asarray(self.std, dtype=dtype)\n",
    "        if np.any(self.std) == 0:\n",
    "            raise ValueError(f\"std evaluated to zero after conversion to {dtype}, \"\n",
    "                             f\"leading to division by zero.\")\n",
    "        if mean.ndim == 1:\n",
    "            mean = einops.rearrange(mean, 'C -> 1 1 C')\n",
    "        if std.ndim == 1:\n",
    "            std = einops.rearrange(std, 'C -> 1 1 C')\n",
    "        \n",
    "        return (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    dtype = jnp.float32\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        batch_size, seq_len, emb_dim = x.shape\n",
    "        pos_emb_shape = (1, seq_len, emb_dim)\n",
    "        pe = self.param('positional_embedding', \n",
    "                        nn.initializers.normal(stddev=0.02), pos_emb_shape)\n",
    "        return x + pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    num_hiddens: int\n",
    "    dtype = jnp.float32\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jax.Array):\n",
    "        x = einops.rearrange(\n",
    "            x, \"... (H PH) (W PW) C -> ... (H W) (PH PW C)\",\n",
    "            PH=patch_size, PW=patch_size\n",
    "        )\n",
    "        x = nn.Dense(self.num_hiddens, dtype=self.dtype)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    hidden_dim: int\n",
    "    dropout_rate: float\n",
    "    dtype = jnp.float32\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train):\n",
    "        out_dim = x.shape[-1]\n",
    "        x = nn.Dense(self.hidden_dim, \n",
    "                     kernel_init=nn.initializers.xavier_uniform())(x)\n",
    "        x = nn.gelu(x)\n",
    "        x = nn.Dropout(self.dropout_rate, deterministic=not train)(x)\n",
    "        x = nn.Dense(out_dim, dtype=self.dtype,\n",
    "                     kernel_init=nn.initializers.xavier_uniform())(x)\n",
    "        x = nn.Dropout(self.dropout_rate, deterministic=not train)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    mlp_dim: int\n",
    "    num_heads: int\n",
    "    dropout_rate: float = 0.1\n",
    "    attention_dropout_rate: float = 0.1\n",
    "    dtype = jnp.float32\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, train):\n",
    "        x = nn.LayerNorm()(inputs)\n",
    "        x = nn.MultiHeadDotProductAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            dropout_rate=self.attention_dropout_rate,\n",
    "            deterministic=not train,\n",
    "            kernel_init=nn.initializers.xavier_uniform()\n",
    "        )(x)\n",
    "        x = nn.Dropout(self.dropout_rate, deterministic=not train)(x)\n",
    "        x = x + inputs\n",
    "\n",
    "        # mlp\n",
    "        y = nn.LayerNorm()(x)\n",
    "        y = MLP(self.mlp_dim, self.dropout_rate)(y, train)\n",
    "        return x + y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    num_classes: int\n",
    "    num_layers: int\n",
    "    hidden_dim: int\n",
    "    num_heads: int\n",
    "    mlp_dim: int\n",
    "    dropout_rate: float\n",
    "    attention_dropout_rate: float\n",
    "    dtype = jnp.float32\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train):\n",
    "        B, H, W, C = x.shape\n",
    "        \n",
    "        x = PatchEmbedding(self.hidden_dim)(x)\n",
    "        cls_token = self.param('cls_token', \n",
    "                               nn.initializers.normal(stddev=0.02), \n",
    "                               (1, 1, self.hidden_dim))\n",
    "        cls_token = jnp.tile(cls_token, (B, 1, 1)) # (B, 1, hidden_dim)\n",
    "        x = jnp.concatenate([cls_token, x], axis=1)\n",
    "        \n",
    "        x = PositionalEmbedding()(x)\n",
    "        x = nn.Dropout(self.dropout_rate, deterministic=not train)(x)\n",
    "        for _ in range(self.num_layers):\n",
    "            x = EncoderBlock(self.mlp_dim, self.num_heads, \n",
    "                             self.dropout_rate, self.attention_dropout_rate)(x, train)\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = x[:, 0]\n",
    "        x = nn.Dense(self.num_classes)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.value_and_grad\n",
    "def compute_grad(\n",
    "    params,\n",
    "    model: nn.Module,\n",
    "    batch: tuple[jnp.ndarray, jnp.ndarray],\n",
    "    key: jrand.PRNGKey,\n",
    "):\n",
    "    img, label = batch\n",
    "    logits = model.apply(params, img, rngs={'dropout': key}, train=True)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, label)\n",
    "    return loss.mean()\n",
    "\n",
    "@ft.partial(jax.jit, static_argnums=(1, 2))\n",
    "def step(\n",
    "    params,\n",
    "    model: nn.Module,\n",
    "    opt: optax.GradientTransformation,\n",
    "    opt_state: optax.OptState,\n",
    "    batch: tuple[jnp.ndarray, jnp.ndarray],\n",
    "    key: jrand.PRNGKey,\n",
    "):\n",
    "    loss, grads = compute_grad(params, model, batch, key)\n",
    "    updates, opt_state = opt.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state, loss\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: optax.GradientTransformation,\n",
    "    data_loader: jdl.DataLoader,\n",
    "    epochs: int,\n",
    "    rng_key: jrand.PRNGKey = jrand.PRNGKey(0),\n",
    "):\n",
    "    rng_key, init_key = jrand.split(rng_key)\n",
    "    xs, ys = next(iter(data_loader))\n",
    "    params = model.init(init_key, xs, train=False)\n",
    "    opt_state = optimizer.init(params)\n",
    "    losses, steps = [], 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in data_loader:\n",
    "            rng_key, key = jrand.split(rng_key)\n",
    "            params, opt_state, loss = step(\n",
    "                params, model, optimizer, opt_state, batch, key\n",
    "            )\n",
    "            losses.append(loss)\n",
    "            steps += 1\n",
    "\n",
    "            if steps % 500 == 0:\n",
    "                print(f\"Epoch: {epoch}, Step: {steps}, Loss: {loss}\")\n",
    "    return params, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 3e-4\n",
    "dropout_rate = 0.1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.99\n",
    "batch_size = 64 * 2 * 2\n",
    "patch_size = 4\n",
    "num_patches = 64\n",
    "num_steps = 100000\n",
    "image_size = (32, 32, 3)\n",
    "embedding_dim = 512\n",
    "hidden_dim = 256\n",
    "num_heads = 8\n",
    "num_layers = 4\n",
    "height, width, channels = image_size\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /tmp/CIFAR/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:02<00:00, 63361930.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/CIFAR/cifar-10-python.tar.gz to /tmp/CIFAR/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.Resize((height, width)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        ToNumpy(),\n",
    "        Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Resize((height, width)),\n",
    "        ToNumpy(),\n",
    "        Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    \"/tmp/CIFAR/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train,\n",
    "\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    \"/tmp/CIFAR/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = ViT(\n",
    "    num_classes=num_classes,\n",
    "    num_layers=num_layers,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_heads=num_heads,\n",
    "    mlp_dim=embedding_dim,\n",
    "    dropout_rate=dropout_rate,\n",
    "    attention_dropout_rate=dropout_rate,\n",
    ")\n",
    "schedule_fn = optax.warmup_cosine_decay_schedule(\n",
    "    init_value=0.0, peak_value=lr, warmup_steps=500, decay_steps=10_000\n",
    ")\n",
    "opt = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),\n",
    "    optax.adamw(learning_rate=schedule_fn, b1=beta1, b2=beta2),\n",
    ")\n",
    "dl = jdl.DataLoader(train_dataset, 'pytorch', batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, losses = train(vit, opt, dl, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8149\n"
     ]
    }
   ],
   "source": [
    "corrects = []\n",
    "\n",
    "dl = jdl.DataLoader(test_dataset, 'pytorch', batch_size=batch_size * 4, shuffle=True)\n",
    "for batch in dl:\n",
    "    img, label = batch\n",
    "    logits = vit.apply(params, img, rngs={'dropout': jrand.PRNGKey(0)}, train=False)\n",
    "    preds = jnp.argmax(logits, axis=-1)\n",
    "    corrects.append((preds == label))\n",
    "\n",
    "print(f\"Accuracy: {np.concatenate(corrects).mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
