{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader for JAX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Python](https://img.shields.io/pypi/pyversions/jax-dataloader.svg)\n",
    "![CI status](https://github.com/BirkhoffG/jax-dataloader/actions/workflows/nbdev.yaml/badge.svg)\n",
    "![Docs](https://github.com/BirkhoffG/jax-dataloader/actions/workflows/deploy.yaml/badge.svg)\n",
    "![pypi](https://img.shields.io/pypi/v/jax-dataloader.svg)\n",
    "![GitHub License](https://img.shields.io/github/license/BirkhoffG/jax-dataloader.svg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "`jax_dataloader` provides a high-level *pytorch-like* dataloader API for `jax`. \n",
    "It supports\n",
    "\n",
    "* **downloading and pre-processing datasets** via [huggingface datasets](https://github.com/huggingface/datasets), [pytorch Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset), and tensorflow dataset (forthcoming)\n",
    "\n",
    "* **iteratively loading batches** via (vanillla) [jax dataloader](https://birkhoffg.github.io/jax-dataloader/core.html#jax-dataloader), [pytorch dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), tensorflow (forthcoming), and merlin (forthcoming).\n",
    "\n",
    "\n",
    "A minimum `jax_dataloader` example:\n",
    "\n",
    "```python\n",
    "import jax_dataloader as jdl\n",
    "\n",
    "dataloader = jdl.DataLoader(\n",
    "    dataset, # Can be a jdl.Dataset or pytorch or huggingface dataset\n",
    "    backend='jax', # Use 'jax' for loading data (also supports `pytorch`)\n",
    ")\n",
    "\n",
    "batch = next(iter(dataloader)) # iterate next batch\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "The latest `jax_dataloader` release can directly be installed from PyPI:\n",
    "\n",
    "```sh\n",
    "pip install jax_dataloader\n",
    "```\n",
    "\n",
    "or install directly from the repository:\n",
    "\n",
    "```sh\n",
    "pip install git+https://github.com/BirkhoffG/jax-dataloader.git\n",
    "```\n",
    "\n",
    ":::{.callout-note} \n",
    "\n",
    "We will only install `jax`-related dependencies. \n",
    "If you wish to use integration of `pytorch` or huggingface `datasets`,\n",
    "you should try to manually install them, \n",
    "or run `pip install jax_dataloader[all]` for installing all the dependencies.\n",
    "\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "`jax_dataloader.core.DataLoader` follows similar API as the pytorch dataloader.\n",
    "\n",
    "* The `dataset` argument takes `jax_dataloader.core.Dataset` \n",
    "or `torch.utils.data.Dataset` or (the huggingface) `datasets.Dataset`\n",
    "as an input from which to load the data.\n",
    "* The `backend` argument takes `\"jax\"` or`\"pytorch\"` as an input,\n",
    "which specifies which backend dataloader to use batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax_dataloader as jdl\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `ArrayDataset`\n",
    "\n",
    "The `jax_dataloader.core.ArrayDataset` is an easy way to wrap \n",
    "multiple `jax.numpy.array` into one Dataset. For example, \n",
    "we can create an `ArrayDataset` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "# Create features `X` and labels `y`\n",
    "X = jnp.arange(100).reshape(10, 10)\n",
    "y = jnp.arange(10)\n",
    "# Create an `ArrayDataset`\n",
    "arr_ds = jdl.ArrayDataset(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `arr_ds` can be loaded by both `\"jax\"` and `\"pytorch\"` dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "# Create a `DataLoader` from the `ArrayDataset` via jax backend\n",
    "dataloader = jdl.DataLoader(arr_ds, 'jax', batch_size=5, shuffle=True)\n",
    "# Or we can use the pytorch backend\n",
    "dataloader = jdl.DataLoader(arr_ds, 'pytorch', batch_size=5, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pytorch Datasets\n",
    "\n",
    "The [pytorch Dataset](https://pytorch.org/docs/stable/data.html)\n",
    "and its ecosystems (e.g., \n",
    "[torchvision](https://pytorch.org/vision/stable/index.html),\n",
    "[torchtext](https://pytorch.org/text/stable/index.html),\n",
    "[torchaudio](https://pytorch.org/audio/stable/index.html)) \n",
    "supports many built-in datasets. \n",
    "`jax_dataloader` supports directly passing the pytorch Dataset.\n",
    "\n",
    ":::{.callout-note} \n",
    "\n",
    "Unfortuantely, the [pytorch Dataset](https://pytorch.org/docs/stable/data.html)\n",
    "can only work with `backend=pytorch`. See the belowing example.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the MNIST dataset from `torchvision`. \n",
    "The `ToNumpy` object transforms images to `numpy.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToNumpy(object):\n",
    "  def __call__(self, pic):\n",
    "    return np.array(pic, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "pt_ds = MNIST('/tmp/mnist/', download=True, transform=ToNumpy(), train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `pt_ds` can **only** be loaded via `\"pytorch\"` dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "dataloader = jdl.DataLoader(pt_ds, 'pytorch', batch_size=5, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Huggingface Datasets\n",
    "\n",
    "The huggingface [datasets](https://github.com/huggingface/datasets)\n",
    "is a morden library for downloading, pre-processing, and sharing datasets.\n",
    "`jax_dataloader` supports directly passing the huggingface datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hf\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, We load the `\"squad\"` dataset from `datasets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset squad (/home/birk/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386bd682f15e4d079e80e0671de1b611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| output: false\n",
    "#| hf\n",
    "hf_ds = load_dataset(\"squad\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `hf_ds` can be loaded via `\"jax\"` and `\"pytorch\"` dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hf torch\n",
    "# Create a `DataLoader` from the `datasets.Dataset` via jax backend\n",
    "dataloader = jdl.DataLoader(hf_ds['train'], 'jax', batch_size=5, shuffle=True)\n",
    "# Or we can use the pytorch backend\n",
    "dataloader = jdl.DataLoader(hf_ds['train'], 'pytorch', batch_size=5, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
