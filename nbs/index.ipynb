{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader for JAX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Python](https://img.shields.io/pypi/pyversions/jax-dataloader.svg)\n",
    "![CI status](https://github.com/BirkhoffG/jax-dataloader/actions/workflows/nbdev.yaml/badge.svg)\n",
    "![Docs](https://github.com/BirkhoffG/jax-dataloader/actions/workflows/deploy.yaml/badge.svg)\n",
    "![pypi](https://img.shields.io/pypi/v/jax-dataloader.svg)\n",
    "![GitHub License](https://img.shields.io/github/license/BirkhoffG/jax-dataloader.svg)\n",
    "<a href=\"https://static.pepy.tech/badge/jax-dataloader\"><img src=\"https://static.pepy.tech/badge/jax-dataloader\" alt=\"Downloads\"></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "`jax_dataloader` brings *pytorch-like* dataloader API to `jax`. \n",
    "It supports\n",
    "\n",
    "* **4 datasets to download and pre-process data**: \n",
    "    * [jax dataset](https://birkhoffg.github.io/jax-dataloader/dataset/)\n",
    "    * [huggingface datasets](https://github.com/huggingface/datasets) \n",
    "    * [pytorch Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "    * [tensorflow dataset](www.tensorflow.org/datasets)\n",
    "\n",
    "* **3 backends to iteratively load batches**: \n",
    "    * [jax dataloader](https://birkhoffg.github.io/jax-dataloader/core.html#jax-dataloader)\n",
    "    * [pytorch dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) \n",
    "    * [tensorflow dataset](www.tensorflow.org/datasets)\n",
    "\n",
    "\n",
    "A minimum `jax-dataloader` example:\n",
    "\n",
    "```python\n",
    "import jax_dataloader as jdl\n",
    "\n",
    "dataloader = jdl.DataLoader(\n",
    "    dataset, # Can be a jdl.Dataset or pytorch or huggingface dataset\n",
    "    backend='jax', # Use 'jax' for loading data (also supports `pytorch`)\n",
    ")\n",
    "\n",
    "batch = next(iter(dataloader)) # iterate next batch\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "The latest `jax-dataloader` release can directly be installed from PyPI:\n",
    "\n",
    "```sh\n",
    "pip install jax-dataloader\n",
    "```\n",
    "\n",
    "or install directly from the repository:\n",
    "\n",
    "```sh\n",
    "pip install git+https://github.com/BirkhoffG/jax-dataloader.git\n",
    "```\n",
    "\n",
    ":::{.callout-note} \n",
    "\n",
    "We keep `jax-dataloader`'s dependencies minimum, which only install `jax`-related dependencies, and `plum-dispatch` for backend dispatching.\n",
    "If you wish to use integration of `pytorch`, huggingface `datasets`, or `tensorflow`,\n",
    "we recommend manually install those dependencies.\n",
    "\n",
    "You can also run `pip install jax-dataloader[all]` to install everything (not recommended).\n",
    "\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "`jax_dataloader.core.DataLoader` follows similar API as the pytorch dataloader.\n",
    "\n",
    "* The `dataset` should be an object of the subclass of `jax_dataloader.core.Dataset` \n",
    "or `torch.utils.data.Dataset` or (the huggingface) `datasets.Dataset`\n",
    "or `tf.data.Dataset`.\n",
    "* The `backend` should be one of `\"jax\"` or `\"pytorch\"` or `\"tensorflow\"`. \n",
    "This argument specifies which backend dataloader to load batches.\n",
    "\n",
    "Note that not every dataset is compatible with every backend. See the compatibility table below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "from IPython.display import Markdown\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from jax_dataloader.core import get_backend_compatibilities, SUPPORTED_DATASETS, JAXDataset\n",
    "from jax_dataloader.imports import *\n",
    "import pandas as pd\n",
    "import jax_dataloader as jdl\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|                | `jdl.Dataset`   | `torch_data.Dataset`   | `tf.data.Dataset`   | `datasets.Dataset`   |\n",
       "|:---------------|:----------------|:-----------------------|:--------------------|:---------------------|\n",
       "| `\"jax\"`        | ✅              | ❌                     | ❌                  | ✅                   |\n",
       "| `\"pytorch\"`    | ✅              | ✅                     | ❌                  | ✅                   |\n",
       "| `\"tensorflow\"` | ✅              | ❌                     | ✅                  | ✅                   |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "compat = get_backend_compatibilities()\n",
    "annotate = {\n",
    "    JAXDataset: \"`jdl.Dataset`\",\n",
    "    TorchDataset: \"`torch_data.Dataset`\",\n",
    "    TFDataset: \"`tf.data.Dataset`\",\n",
    "    HFDataset: \"`datasets.Dataset`\",\n",
    "}\n",
    "assert len(annotate) == len(SUPPORTED_DATASETS)\n",
    "supported = {}\n",
    "\n",
    "for backend, ds in compat.items():\n",
    "    if len(ds) > 0:\n",
    "        _supported = [s in ds for s in SUPPORTED_DATASETS]\n",
    "        supported[f'`\"{backend}\"`'] = list(map(lambda x: \"✅\" if x else \"❌\", _supported))\n",
    "\n",
    "Markdown(\n",
    "    pd.DataFrame(supported)\n",
    "    .T\n",
    "    .rename(columns={\"index\": \"Backend\"})\n",
    "    .rename(columns={i: annotated for i, annotated in enumerate(annotate.values())})\n",
    "    .to_markdown()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `ArrayDataset`\n",
    "\n",
    "The `jax_dataloader.core.ArrayDataset` is an easy way to wrap \n",
    "multiple `jax.numpy.array` into one Dataset. For example, \n",
    "we can create an `ArrayDataset` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "# Create features `X` and labels `y`\n",
    "X = jnp.arange(100).reshape(10, 10)\n",
    "y = jnp.arange(10)\n",
    "# Create an `ArrayDataset`\n",
    "arr_ds = jdl.ArrayDataset(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `arr_ds` can be loaded by *every* backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "# Create a `DataLoader` from the `ArrayDataset` via jax backend\n",
    "dataloader = jdl.DataLoader(arr_ds, 'jax', batch_size=5, shuffle=True)\n",
    "# Or we can use the pytorch backend\n",
    "dataloader = jdl.DataLoader(arr_ds, 'pytorch', batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Huggingface Datasets\n",
    "\n",
    "The huggingface [datasets](https://github.com/huggingface/datasets)\n",
    "is a morden library for downloading, pre-processing, and sharing datasets.\n",
    "`jax_dataloader` supports directly passing the huggingface datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hf\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, We load the `\"squad\"` dataset from `datasets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| hf\n",
    "hf_ds = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use `jax_dataloader` to load batches of `hf_ds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hf torch\n",
    "# Create a `DataLoader` from the `datasets.Dataset` via jax backend\n",
    "dataloader = jdl.DataLoader(hf_ds['train'], 'jax', batch_size=5, shuffle=True)\n",
    "# Or we can use the pytorch backend\n",
    "dataloader = jdl.DataLoader(hf_ds['train'], 'pytorch', batch_size=5, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pytorch Datasets\n",
    "\n",
    "The [pytorch Dataset](https://pytorch.org/docs/stable/data.html)\n",
    "and its ecosystems (e.g., \n",
    "[torchvision](https://pytorch.org/vision/stable/index.html),\n",
    "[torchtext](https://pytorch.org/text/stable/index.html),\n",
    "[torchaudio](https://pytorch.org/audio/stable/index.html)) \n",
    "supports many built-in datasets. \n",
    "`jax_dataloader` supports directly passing the pytorch Dataset.\n",
    "\n",
    ":::{.callout-note} \n",
    "\n",
    "Unfortuantely, the [pytorch Dataset](https://pytorch.org/docs/stable/data.html)\n",
    "can only work with `backend=pytorch`. See the belowing example.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the MNIST dataset from `torchvision`. \n",
    "The `ToNumpy` object transforms images to `numpy.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToNumpy(object):\n",
    "  def __call__(self, pic):\n",
    "    return np.array(pic, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "pt_ds = MNIST('/tmp/mnist/', download=True, transform=ToNumpy(), train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `pt_ds` can **only** be loaded via `\"pytorch\"` dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "dataloader = jdl.DataLoader(pt_ds, 'pytorch', batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensowflow Datasets\n",
    "\n",
    "`jax_dataloader` supports directly passing the [tensorflow datasets](www.tensorflow.org/datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we can load the MNIST dataset from `tensorflow_datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ds = tfds.load('mnist', split='test', as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use `jax_dataloader` for iterating the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = jdl.DataLoader(tf_ds, 'tensorflow', batch_size=5, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
