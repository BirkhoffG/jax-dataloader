{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loaders.jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 22:18:26.142014: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-01 22:18:26.142138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-01 22:18:26.151662: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-01 22:18:26.979728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from __future__ import print_function, division, annotations\n",
    "from jax_dataloader.imports import *\n",
    "from jax_dataloader.datasets import ArrayDataset, JAXDataset\n",
    "from jax_dataloader.loaders import BaseDataLoader\n",
    "from jax_dataloader.utils import get_config, asnumpy\n",
    "from jax_dataloader.tests import *\n",
    "import jax_dataloader as jdl\n",
    "from threading import Thread, Event\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def chunk(seq: Sequence, size: int) -> List[Sequence]:\n",
    "    return [seq[pos:pos + size] for pos in range(0, len(seq), size)]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def EpochIterator(\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    indices: Sequence[int]\n",
    "):\n",
    "    for i in range(0, len(indices), batch_size):\n",
    "        idx = indices[i:i+batch_size]\n",
    "        yield data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MultiprocessIterator(Thread):\n",
    "    \"\"\"[WIP] Multiprocessing Epoch Iterator\"\"\"\n",
    "    \n",
    "    def __init__(self, data, batch_size: int, indices=None):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        indices = np.arange(len(data)) if indices is None else indices\n",
    "        batches = chunk(indices, batch_size)\n",
    "        self.iter_idx = iter(batches)\n",
    "        self.output_queue = Queue() # TODO: maxsize\n",
    "        self.terminate_event = Event()\n",
    "        self.start()\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            while True:\n",
    "                result = self.get_data()\n",
    "                self.output_queue.put(result)\n",
    "        except StopIteration:\n",
    "            self.output_queue.put(None)\n",
    "\n",
    "    def __next__(self):\n",
    "        result = self.output_queue.get()\n",
    "        if result is None:\n",
    "            self.close()\n",
    "            raise StopIteration()\n",
    "        return result\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "\n",
    "    def close(self):\n",
    "        self.terminate_event.set()\n",
    "\n",
    "    def get_data(self):\n",
    "        batch_idx = next(self.iter_idx)\n",
    "        batch = self.data[batch_idx]\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dispatch\n",
    "def to_jax_dataset(dataset: JAXDataset):\n",
    "    if isinstance(dataset, ArrayDataset):\n",
    "        dataset.asnumpy()\n",
    "    return dataset\n",
    "\n",
    "@dispatch\n",
    "def to_jax_dataset(dataset: HFDataset):\n",
    "    return dataset.with_format('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataLoaderJAX(BaseDataLoader):\n",
    "\n",
    "    @typecheck\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataset: Union[JAXDataset, HFDataset], \n",
    "        batch_size: int = 1,  # batch size\n",
    "        shuffle: bool = False,  # if true, dataloader shuffles before sampling each batch\n",
    "        num_workers: int = 0,  # how many subprocesses to use for data loading. Ignored.\n",
    "        drop_last: bool = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.key = jrand.PRNGKey(get_config().global_seed)\n",
    "        self.dataset = to_jax_dataset(dataset)\n",
    "        \n",
    "        self.indices = np.arange(len(dataset))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # shuffle (permutation) indices every epoch        \n",
    "        indices = jrand.permutation(self.next_key(), self.indices).__array__() if self.shuffle else self.indices\n",
    "        \n",
    "        if self.drop_last:\n",
    "            indices = indices[:len(self.indices) - len(self.indices) % self.batch_size]\n",
    "        return EpochIterator(self.dataset, self.batch_size, indices)\n",
    "    \n",
    "    def next_key(self):\n",
    "        self.key, subkey = jrand.split(self.key)\n",
    "        return subkey\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size + int(not self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1280\n",
    "batch_size = 12\n",
    "feats = np.arange(samples).repeat(10).reshape(samples, 10)\n",
    "labels = np.arange(samples).reshape(samples, 1)\n",
    "ds = ArrayDataset(feats, labels)\n",
    "dl = DataLoaderJAX(ds, batch_size=batch_size, shuffle=True)\n",
    "assert len(dl) == 1280 // 12 + 1\n",
    "assert len(dl.indices) == 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_dataloader(DataLoaderJAX, samples=20, batch_size=12)\n",
    "test_dataloader(DataLoaderJAX, samples=20, batch_size=10)\n",
    "test_dataloader(DataLoaderJAX, samples=11, batch_size=10)\n",
    "test_dataloader(DataLoaderJAX, samples=40, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_dataloader(DataLoaderJAX, ds_type='hf', samples=40, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 ms ± 27.8 ms per loop (mean ± std. dev. of 3 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 3\n",
    "test_dataloader(DataLoaderJAX, samples=1280, batch_size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
