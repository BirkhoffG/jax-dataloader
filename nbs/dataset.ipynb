{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import print_function, division, annotations\n",
    "from jax_dataloader.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dataset:\n",
    "    \"\"\"A pytorch-like Dataset class.\"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ArrayDataset(Dataset):\n",
    "    \"\"\"Dataset wrapping numpy arrays.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        *arrays: jax.Array # Numpy array with same first dimension\n",
    "    ):\n",
    "        assert all(arrays[0].shape[0] == arr.shape[0] for arr in arrays), \\\n",
    "            \"All arrays must have the same dimension.\"\n",
    "        self.arrays = tuple(arrays)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.arrays[0].shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return jax.tree_util.tree_map(lambda x: x[index], self.arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to [torch.utils.data.TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset), \n",
    "but it wrapps numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "X = jnp.arange(10000).reshape(1000, 10)\n",
    "y = jnp.arange(1000)\n",
    "ds = ArrayDataset(X, y)\n",
    "assert len(ds) == 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We index numpy arrays along the first dimension. Dataset indexing is done via `ds[index]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = ds[1] # get the first sample\n",
    "assert jnp.array_equal(x1, X[1])\n",
    "assert jnp.array_equal(y1, y[1])\n",
    "\n",
    "x10, y10 = ds[:10]\n",
    "assert jnp.array_equal(x10, X[:10])\n",
    "assert jnp.array_equal(y10, y[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
