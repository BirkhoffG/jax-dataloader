{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n",
    "\n",
    "> Global configs, PRNGSequence, check installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "from nbdev import show_doc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import print_function, division, annotations\n",
    "from jax_dataloader.imports import *\n",
    "import jax_dataloader as jdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Global configuration for the library\"\"\"\n",
    "    rng_reserve_size: int\n",
    "    global_seed: int\n",
    "\n",
    "    @classmethod\n",
    "    def default(cls) -> Config:\n",
    "        return cls(rng_reserve_size=1, global_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "main_config = Config.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_config() -> Config:\n",
    "    return main_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PRNGSequence(Iterator[PRNGKey]):\n",
    "    \"\"\"An Interator of Jax PRNGKey (minimal version of `haiku.PRNGSequence`).\"\"\"\n",
    "\n",
    "    def __init__(self, seed: int):\n",
    "        self._key = jax.random.PRNGKey(seed)\n",
    "        self._subkeys = collections.deque()\n",
    "\n",
    "    def reserve(self, num):\n",
    "        \"\"\"Splits additional ``num`` keys for later use.\"\"\"\n",
    "        if num > 0:\n",
    "            new_keys = tuple(jax.random.split(self._key, num + 1))\n",
    "            self._key = new_keys[0]\n",
    "            self._subkeys.extend(new_keys[1:])\n",
    "            \n",
    "    def __next__(self):\n",
    "        if not self._subkeys:\n",
    "            self.reserve(get_config().rng_reserve_size)\n",
    "        return self._subkeys.popleft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "keys = PRNGSequence(0)\n",
    "key_1 = next(keys)\n",
    "key_2 = next(keys)\n",
    "assert key_1 is not key_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_pytorch_installed():\n",
    "    if torch_data is None:\n",
    "        raise ModuleNotFoundError(\"`pytorch` library needs to be installed. \"\n",
    "            \"Try `pip install torch`. Please refer to pytorch documentation for details: \"\n",
    "            \"https://pytorch.org/get-started/.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| torch\n",
    "check_pytorch_installed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def has_pytorch_tensor(batch) -> bool:\n",
    "    if isinstance(batch[0], torch.Tensor):\n",
    "        return True\n",
    "    elif isinstance(batch[0], (tuple, list)):\n",
    "        transposed = zip(*batch)\n",
    "        return any([has_pytorch_tensor(samples) for samples in transposed])\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_hf_installed():\n",
    "    if hf_datasets is None:\n",
    "        raise ModuleNotFoundError(\"`datasets` library needs to be installed. \"\n",
    "            \"Try `pip install datasets`. Please refer to huggingface documentation for details: \"\n",
    "            \"https://huggingface.co/docs/datasets/installation.html.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hf\n",
    "check_hf_installed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_tf_installed():\n",
    "    if tf is None:\n",
    "        raise ModuleNotFoundError(\"`tensorflow` library needs to be installed. \"\n",
    "            \"Try `pip install tensorflow`. Please refer to tensorflow documentation for details: \"\n",
    "            \"https://www.tensorflow.org/install/pip.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| tf\n",
    "check_tf_installed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_hf_dataset(dataset):\n",
    "    return hf_datasets and (\n",
    "        isinstance(dataset, hf_datasets.Dataset) \n",
    "        or isinstance(dataset, hf_datasets.DatasetDict)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_torch_dataset(dataset):\n",
    "    return torch_data and isinstance(dataset, torch_data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_jdl_dataset(dataset):\n",
    "    return isinstance(dataset, jdl.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_tf_dataset(dataset):\n",
    "    return tf and isinstance(dataset, tf.data.Dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
